---
title: "project code"
author: "Rob McNeil and Jessica Chaffee"
date: "2024-11-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


***Note: if we want do run model selection, run cross-validation on training set first,
then on test set. if no model selection, just run cross-validationw

***note: im thinking based on the size of the dataset, we use cross-validation, its defensible to not perform gradient descent due to risk of overfitting the data 

**random forest models at the bottom of the program that looked at tkvd_change outcome prediction

Load library, import data set, spit training and testing data

```{r}
library(caret)
library(randomForest)
library(ggplot2)
library(ggcorrplot)
library(dplyr)
library(glmnet)
library(elasticnet)


#linux pathway
#adpkd <- read.csv("/home/robmcneil/Documents/advanced_data/Project3_data.csv")
adpkd <- read.csv("~/Downloads/Project3_data.csv")
#windows pathway 
#adpkd <-read.csv("C:\Users\rrm10\OneDrive\Desktop\advanced data analysis\Project3_data.csv")

str(adpkd)

# code to do a 70/30, most likely will go with K fold
#set.seed(123)
#randomly split data into 70/30 
#sample <- sample(c(TRUE, FALSE), nrow(adpkd), replace=TRUE,prob=c(0.7,0.3))
#training <-adpkd[sample, ]
#testing <- adpkd[!sample,]

#using k-fold 5 validation 

ctrl <-trainControl(method = "cv",
                    number = 5,
                    savePredictions = "final",
                    summaryFunction = defaultSummary 
)
    



```

```{r}
#summary of missing data (Found no missing data)
colSums(is.na(adpkd))
```

```{r}
# Visualize data via histograms of numeric variables
numeric_columns <- sapply(adpkd, is.numeric)

for (col in names(adpkd)[numeric_columns]) {
  hist(adpkd[[col]], main = paste("Histogram of", col), xlab = col)
}
```
```{r}
#shapiro wilkd test for normality(not great)
shapiro_results <- lapply(adpkd[, numeric_columns], shapiro.test)

shapiro_results
```

```{r}
# Get correlation matrix
numeric_columns <- sapply(adpkd, is.numeric)
cor_matrix <- cor(adpkd[, numeric_columns])   

#visualize correlation matrix
print(cor_matrix)

```


```{r}
# Get highly correlated features
high_correlations <- which(abs(cor_matrix) > 0.8, arr.ind = TRUE)

high_correlations_pairs <- data.frame(
  Column1 = rownames(cor_matrix)[high_correlations[, 1]],
  Column2 = colnames(cor_matrix)[high_correlations[, 2]],
  Correlation = cor_matrix[high_correlations]
)

# Print the result
high_correlations_pairs

#Finds that lbp4-lbp3, and lbp4-lbp1, are the only feature pairs with a correlation greater than 0.8

```

```{r}
# Address multicolinearity
# ibp4 is highly correlated with both lbp1 and lbp3, lbp4 is also the least correlated with our outcome variables so that is the feature we will delete to address the multicolinearity 

adpkd_no_multico <- adpkd[, -which(names(adpkd)== "lbp4")]
head(adpkd_no_multico)

#adpkd_no_multico is the dataset without lbp4 to address issues with multicolinearity
```
```{r}
# box plots of independent variables 
vars_to_transform <- setdiff(names(adpkd_no_multico), c("Subject.ID", "tkvht_visit2","progression","tkvht_change"))
x_variables <- adpkd_no_multico[, vars_to_transform]

for (col in names(x_variables)) {
  boxplot(x_variables[[col]], main = paste("Boxplot of", col), ylab = col)
}

# While the box plots do show that we have outliers we do not have any evidence that these outliers are an error, for now we will leave them in until we decide on the features that we are keeping and then we will revisit how to address them (possibly z-score 3 std's away)
```
```{r}
# Because the values are not normally distributed we decided to use normalization over standardization 

#normalizing x values to put them on a similar scale for analysis 
adpkd_x_vars_normalized <- as.data.frame(lapply(x_variables, function(x) {
  (x - min(x)) / (max(x) - min(x))
}))

head(adpkd_x_vars_normalized)

#normalized to a range between 0 and 1
```
Task 1: For part 2 and part 3 we should do a linear regression, a ridge regression and a lasso regression so that we can compare them and decide on which linear model works best, then we can choose the model that gives us the best AIC and lowest mse as our final model for that part 

```{r}
y_variables <- adpkd_no_multico[, c("Subject.ID", "tkvht_visit2","progression","tkvht_change")]
y_variables
```
```{r}
combined_normalized <- cbind(adpkd_x_vars_normalized, y_variables)
combined_normalized
```

```{r}
# Task 1 Part 1: Linear Model

#model using height-corrected total kidney volume
model_tkv <- train(
  tkvht_change ~ tkvht_base,    # Formula for the model
  data = combined_normalized,               
  method = "lm",               # Linear model (lm)
  trControl = ctrl,            # Cross-validation control
  
)

summary(model_tkv)

#extract residuals

model_tkv_fitted<- predict(model_tkv)
model_tkv_resid <-  resid(model_tkv)



# check assumptions of linear regression on this model

#plot residuals
ggplot(data= NULL, aes(x=model_tkv_fitted,y=model_tkv_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure: tkv change lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_tkv_resid, main = "Q-Q Plot of Residuals for model imaging lm")
qqline(model_tkv_resid, col= "red")



```

```{r}

# # Task 1 Part 2 Model 1: linear model Using only image features
#look at feature engineering
model_image <- train(
  tkvht_change ~ geom1 + geom2 + #image feature based on kidney geometry information
    gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + 
    glcm1 + glcm2 + #image feature based on gray level co-occurrence matrix
    txti1 + txti2 + txti3 + txti4 + txti5 + #image feature based on image textures
    lbp1 + lbp2 + lbp3 + lbp5, # local binary pattern
  data =  combined_normalized,
  method = "lm",
  trControl=ctrl, #cross validation control 
  #preProcess = c("center","scale")
  ) #preprossing 


#extract residuals

model_image_fitted<- predict(model_image)
model_image_resid <-  resid(model_image)

#plot residuals
ggplot(data= NULL, aes(x=model_image_fitted,y=model_image_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure: model imaging lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_image_resid, main = "Q-Q Plot of Residuals for model imaging lm")
qqline(model_image_resid, col= "red")

#appears as though normality could be violated, this could be due to outliers



# Print the results
print(model_image)
```


```{r}

# # Task 1 Part 2 Model 2: lasso model Using only image features
#look at feature engineering
model_image <- train(
  tkvht_change ~ geom1 + geom2 + #image feature based on kidney geometry information
    gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + 
    glcm1 + glcm2 + #image feature based on gray level co-occurrence matrix
    txti1 + txti2 + txti3 + txti4 + txti5 + #image feature based on image textures
    lbp1 + lbp2 + lbp3 + lbp5, # local binary pattern
  data =  combined_normalized,
  method = "lasso",
  trControl=ctrl, #cross validation control 
  #preProcess = c("center","scale")
  ) #preprossing 


#extract residuals

model_image_fitted<- predict(model_image)
model_image_resid <-  resid(model_image)

#plot residuals
ggplot(data= NULL, aes(x=model_image_fitted,y=model_image_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure: model imaging lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_image_resid, main = "Q-Q Plot of Residuals for model imaging lasso")
qqline(model_image_resid, col= "red")

#appears as though normality could be violated, this could be due to outliers



# Print the results
print(model_image)

```



```{r}
# # Task 1 Part 2 Model 3: ridge model Using only image features
#look at feature engineering
model_image <- train(
  tkvht_change ~ geom1 + geom2 + #image feature based on kidney geometry information
    gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + 
    glcm1 + glcm2 + #image feature based on gray level co-occurrence matrix
    txti1 + txti2 + txti3 + txti4 + txti5 + #image feature based on image textures
    lbp1 + lbp2 + lbp3 + lbp5, # local binary pattern
  data =  combined_normalized,
  method = "ridge",
  trControl=ctrl, #cross validation control 
  #preProcess = c("center","scale")
  ) #preprossing 


#extract residuals

model_image_fitted<- predict(model_image)
model_image_resid <-  resid(model_image)

#plot residuals
ggplot(data= NULL, aes(x=model_image_fitted,y=model_image_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure: model imaging lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_image_resid, main = "Q-Q Plot of Residuals for model imaging ridge")
qqline(model_image_resid, col= "red")

#appears as though normality could be violated, this could be due to outliers



# Print the results
print(model_image)
```


Data scaling/normalization
Outlier detection with visualization

data visualization? 
correlation matrix? 
```{r}

#check distribution of progression

table(adpkd$progression)
#binary outcome is evenly distributed 


sum(is.na(adpkd$progression))
#no missing outcomes

#convert progression to factor
adpkd$progression <-factor(adpkd$progression,levels = c(0,1))


```

Data visualization

```{r}

#data visualizations recommendations from AI
corr_matrix <- cor(adpkd[, c("tkvht_base", "geom1","geom2", "gabor1", "gabor2","gabor3","gabor4","gabor5","glcm1","glcm2","txti1","txti2","txti3","txti4","txti5","lbp1","lbp2","lbp3","lbp4","lbp5" )], use = "complete.obs")
#ggplot2::ggcorrplot(corr_matrix, method = "circle")


#outlierdetection  or scatter plot
#appears as though outliers in low base and high baseline measurement are causing issues with homoscadascity 
ggplot(adpkd, aes(x = tkvht_base, y=tkvht_change)) + 
  geom_point()



#feature visualization
ggplot(adpkd, aes(x = tkvht_base, y = tkvht_change, color = progression)) + 
  geom_point() + 
  geom_smooth(method = "lm")

#outliers::
# Fit a model to check for influential points
model <- lm(tkvht_change ~ tkvht_base, data = adpkd)
cooksd <- cooks.distance(model)

# Plot Cook's Distance
ggplot(data = NULL, aes(x = 1:length(cooksd), y = cooksd)) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = 4/(length(cooksd) - length(model$coefficients) - 1), 
             linetype = "dashed", color = "red") +
  labs(title = "Cook's Distance Plot") +
  theme_minimal()


# Get standardized residuals
standardized_resid <- rstandard(model)

# Plot standardized residuals
ggplot(data = NULL, aes(x = 1:length(standardized_resid), y = standardized_resid)) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = c(-2, 2), linetype = "dashed", color = "red") +
  labs(title = "Standardized Residuals") +
  theme_minimal()

```



Models for percent changes predictions 
```{r}

#model using height-corrected total kidney volume
model_tkv <- train(
  tkvht_change ~ tkvht_base,    # Formula for the model
  data = adpkd,               
  method = "lm",               # Linear model (lm)
  trControl = ctrl,            # Cross-validation control
  preProcess = c("center", "scale")  # Preprocessing: center and scale the data
  
)

summary(model_tkv)

#extract residuals

model_tkv_fitted<- predict(model_tkv)
model_tkv_resid <-  resid(model_tkv)



# check assumptions of linear regression on this model

#plot residuals
ggplot(data= NULL, aes(x=model_tkv_fitted,y=model_tkv_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure: tkv change lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_tkv_resid, main = "Q-Q Plot of Residuals for model imaging lm")
qqline(model_tkv_resid, col= "red")


#############

# Model 2: Using only image features
#look at feature engineering
model_image <- train(
  tkvht_change ~ geom1 + geom2 + #image feature based on kidney geometry information
    gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + 
    glcm1 + glcm2 + #image feature based on gray level co-occurrence matrix
    txti1 + txti2 + txti3 + txti4 + txti5 + #image feature based on image textures
    lbp1 + lbp2 + lbp3 + lbp4 + lbp5, # local binary pattern
  data =  adpkd,
  method = "lm",
  trControl=ctrl, #cross validation control 
  preProcess = c("center","scale")) #preprossing 


#extract residuals

model_image_fitted<- predict(model_image)
model_image_resid <-  resid(model_image)

#plot residuals
ggplot(data= NULL, aes(x=model_image_fitted,y=model_image_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure: model imaging lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_image_resid, main = "Q-Q Plot of Residuals for model imaging lm")
qqline(model_image_resid, col= "red")

#appears as though normality could be violated, this could be due to outliers



# Print the results
print(model_image)

# attempted to Check performance comparison across models
#model_image$results

#model 3 (baseline tkvht and image featuring): 

model_both <- train(
  tkvht_change ~ tkvht_base +
    gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + 
    glcm1 + glcm2 + #image feature based on gray level co-occurrence matrix
    txti1 + txti2 + txti3 + txti4 + txti5 + #image feature based on image textures
    lbp1 + lbp2 + lbp3 + lbp4 + lbp5, # local binary pattern 
  data = adpkd,
  method= "lm",
  trControl = ctrl, #cross validation control
  preProcess= c("center", "scale")
    )

####check assumptions 

model_both_fitted<- predict(model_both)
model_both_resid <-  resid(model_both)

#plot residuals
ggplot(data= NULL, aes(x=model_both_fitted,y=model_both_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure: tkv change lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_tkv_resid, main = "Q-Q Plot of Residuals for model imaging lm")
qqline(model_tkv_resid, col= "red")





```


```{r}

#outliers::
# Fit a model to check for influential points
model <- lm(tkvht_change ~ tkvht_base, data = adpkd)
cooksd <- cooks.distance(model)

# Plot Cook's Distance
ggplot(data = NULL, aes(x = 1:length(cooksd), y = cooksd)) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = 4/(length(cooksd) - length(model$coefficients) - 1), 
             linetype = "dashed", color = "red") +
  labs(title = "Cook's Distance Plot") +
  theme_minimal()


# Get standardized residuals
standardized_resid <- rstandard(model)

# Plot standardized residuals
ggplot(data = NULL, aes(x = 1:length(standardized_resid), y = standardized_resid)) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = c(-2, 2), linetype = "dashed", color = "red") +
  labs(title = "Standardized Residuals") +
  theme_minimal()







```

model seletion/ comparion of tvk prediction

```{r}
#initial code from AI reccomendation, using resamples

# Compare models on RSME, R-squared
resamples_list <- resamples(list(model_tkv=model_tkv, model_image=model_image,model_both=model_both))
summary(resamples_list)




```



Models for prediction of progressoin (binary). Getting warnings of perfect seperation

```{r}

#model using height-corrected total kidney volume
model_tkv_pro <- train(
  progression~ tkvht_base,    # Formula for the model
  data = adpkd,               
  method = "glm", 
  family = "binomial",# Linear model (lm)
  trControl = ctrl,            # Cross-validation control
  preProcess = c("center", "scale")  # Preprocessing: center and scale the data
)

summary(model_tkv_pro)

# Model 2: Using only image features
#look at feature engineering
model_image_pro <- train(
  progression~ geom1 + geom2 + #image feature based on kidney geometry information
    gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + 
    glcm1 + glcm2 + #image feature based on gray level co-occurrence matrix
    txti1 + txti2 + txti3 + txti4 + txti5 + #image feature based on image textures
    lbp1 + lbp2 + lbp3 + lbp4 + lbp5, # local binary pattern
  data =  adpkd,
  method = "glm",
  family = "binomial",
  trControl=ctrl, #cross validation control 
  preProcess = c("center","scale")) #preprossing 


# Print the results
print(model_image_pro)

# attempted to Check performance comparison across models
#model_image$results

#model 3 (baseline tkvht and image featuring): 

model_both_pro <- train(
  progression ~ tkvht_base +
    gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + 
    glcm1 + glcm2 + #image feature based on gray level co-occurrence matrix
    txti1 + txti2 + txti3 + txti4 + txti5 + #image feature based on image textures
    lbp1 + lbp2 + lbp3 + lbp4 + lbp5, # local binary pattern 
  data = adpkd,
  method= "glm",
  family = "binomial",
  trControl = ctrl, #cross validation control
  preProcess= c("center", "scale")
    )




```

random forest models: 

```{r}

tune_grid <- expand.grid(
  mtry = 1
)

model_tkv_rf <- train(
  tkvht_change ~ tkvht_base,    # Formula for the model
  data = adpkd,               
  method = "rf",               # Random Forest method
  trControl = ctrl,            # Cross-validation control
  preProcess = c("center", "scale"),  # Preprocessing: center and scale the data
  tuneGrid = tune_grid         # Specify hyperparameter grid
)




# Adjusting tune_grid for Random Forest (model_image)
tune_grid_image <- expand.grid(
  mtry = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)  # Range for number of predictors (image features)
)

# Fit Random Forest model on image features only
model_image_rf <- train(
  tkvht_change ~ geom1 + geom2 + gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + 
    glcm1 + glcm2 + txti1 + txti2 + txti3 + txti4 + txti5 + 
    lbp1 + lbp2 + lbp3 + lbp4 + lbp5,  # Formula with image features
  data = adpkd,
  method = "rf",               # Random Forest method
  trControl = ctrl,            # Cross-validation control
  preProcess = c("center", "scale"),  # Preprocessing: center and scale the data
  tuneGrid = tune_grid_image,  # Tuning mtry
  tuneLength = 5               # Number of tuning steps (can adjust if needed)
)

# Print model results for image features RF model
print(model_image_rf)


# Adjusting tune_grid for Random Forest (model_both)
tune_grid_both <- expand.grid(
  mtry = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16)  # Range for number of predictors (tkvht_base + image features)
)

# Fit Random Forest model on both baseline tkvht_base and image features
model_both_rf <- train(
  tkvht_change ~ tkvht_base + gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + 
    glcm1 + glcm2 + txti1 + txti2 + txti3 + txti4 + txti5 + 
    lbp1 + lbp2 + lbp3 + lbp4 + lbp5,  # Formula with both tkvht_base and image features
  data = adpkd,
  method = "rf",               # Random Forest method
  trControl = ctrl,            # Cross-validation control
  preProcess = c("center", "scale"),  # Preprocessing: center and scale the data
  tuneGrid = tune_grid_both,   # Tuning mtry
  tuneLength = 5               # Number of tuning steps (can adjust if needed)
)

# Print model results for both predictors RF model
print(model_both_rf)

#extract residuals

model_tkvrf_fitted<- predict(model_tkv_rf)
model_tkvrf_resid <-  resid(model_tkv_rf)



# check assumptions of linear regression on this model

#plot residuals
ggplot(data= NULL, aes(x=model_tkvrf_fitted,y=model_tkvrf_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure: tkv change lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_tkvrf_resid, main = "Q-Q Plot of Residuals for model imaging lm")
qqline(model_tkvrf_resid, col= "red")

resamples_list <- resamples(list(model_tkv=model_tkv, model_image=model_image,model_both=model_both))
summary(resamples_list)

resamples_rflist <-resamples(list(model_tkv_rf=model_tkv_rf,
                                  model_image_rf=model_image_rf,
                                  model_both_rf=model_both_rf))
summary(resamples_rflist)




# For model_both_rf
importance(model_both_rf$finalModel)

# Plot feature importance
varImp(model_both_rf)


# Plot the feature importance for visualization

importance_df <- data.frame(Feature = rownames(importance(model_both_rf$finalModel)),
                            Importance = importance(model_both_rf$finalModel)[, 1])

ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Random Forest Feature Importance",
       x = "Feature",
       y = "Importance") 



#after running importance scores this, consider removing features, run a model with base and gabor 4

```


