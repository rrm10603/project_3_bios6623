---
title: "project code"
author: "Rob McNeil and Jessica Chaffee"
date: "2024-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load library, import data set

```{r, echo=FALSE}
library(caret)
library(randomForest)
library(ggplot2)
library(ggcorrplot)
library(knitr)
library(dplyr)
library(tidyr)             
library(glmnet)
library(kableExtra)
library(elasticnet)
library(knitr)
library(pROC)

#linux pathway
#adpkd <- read.csv("/home/robmcneil/Documents/advanced_data/Project3_data.csv")
#adpkd <- read.csv("~/Downloads/Project3_data.csv")
#windows pathway 
adpkd <-read.csv("C:/Users/rrm10/OneDrive/Desktop/advanced data analysis/Project3_data.csv")


```

```{r}
#summary of missing data (Found no missing data)
colSums(is.na(adpkd))
```

```{r}
# Visualize data via histograms of numeric variables
numeric_columns <- sapply(adpkd, is.numeric)

for (col in names(adpkd)[numeric_columns]) {
  hist(adpkd[[col]], main = paste("Figure 1: Histogram of", col), xlab = col)
}
```


```{r}
# Create table 1 

summary_table <- adpkd %>%
  summarise(
    'Geometry Feature 1 (Mean(SD))' = as.character(paste0(formatC(mean(geom1, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(geom1, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Geometry Feature 2 (Mean(SD))' = as.character(paste0(formatC(mean(geom2, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(geom2, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Gabor Transformation 1 (Mean(SD))' = as.character(paste0(formatC(mean(gabor1, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(gabor1, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Gabor Transformation 2 (Mean(SD))' = as.character(paste0(formatC(mean(gabor2, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(gabor2, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Gabor Transformation 3 (Mean(SD))' = as.character(paste0(formatC(mean(gabor3, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(gabor3, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Gabor Transformation 4 (Mean(SD))' = as.character(paste0(formatC(mean(gabor4, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(gabor4, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Gabor Transformation 5 (Mean(SD))' = as.character(paste0(formatC(mean(gabor5, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(gabor5, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Gray Level Co-Occurrence Matrix 1 (Mean(SD))' = as.character(paste0(formatC(mean(glcm1, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(glcm1, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Gray Level Co-Occurrence Matrix 2 (Mean(SD))' = as.character(paste0(formatC(mean(glcm2, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(glcm2, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Image Textures 1 (Mean(SD))' = as.character(paste0(formatC(mean(txti1, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(txti1, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Image Textures 2 (Mean(SD))' = as.character(paste0(formatC(mean(txti2, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(txti2, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Image Textures 3 (Mean(SD))' = as.character(paste0(formatC(mean(txti3, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(txti3, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Image Textures 4 (Mean(SD))' = as.character(paste0(formatC(mean(txti4, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(txti4, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Image Textures 5 (Mean(SD))' = as.character(paste0(formatC(mean(txti5, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(txti5, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Local Binary Pattern 1 (Mean(SD))' = as.character(paste0(formatC(mean(lbp1, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(lbp1, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Local Binary Pattern 2 (Mean(SD))' = as.character(paste0(formatC(mean(lbp2, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(lbp2, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Local Binary Pattern 3 (Mean(SD))' = as.character(paste0(formatC(mean(lbp3, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(lbp3, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Local Binary Pattern 4 (Mean(SD))' = as.character(paste0(formatC(mean(lbp4, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(lbp4, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Local Binary Pattern 5 (Mean(SD))' = as.character(paste0(formatC(mean(lbp5, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(lbp5, na.rm = TRUE), format = "e", digits = 2), ")")),
    'Baseline Hight-Corrected Total Kidney Volume (Mean(SD))' = as.character(paste0(formatC(mean(tkvht_base, na.rm = TRUE), format = "e", digits = 2), " (", formatC(sd(tkvht_base, na.rm = TRUE), format = "e", digits = 2), ")")),
  ) %>%
  pivot_longer(cols = everything(), names_to = "Characteristic", values_to = "Value") 
    

# Print the table
kable(summary_table, caption = "Table 1: Baseline Characteristics of Study Participants") %>%
  kable_styling() %>%
  row_spec(0, bold = TRUE) %>% # Bold the header
  row_spec(1:nrow(summary_table), extra_css = "border-top: 1px solid black; border-bottom: 1px solid black;")

```


```{r}
#shapiro wilkd test for normality(not great)
shapiro_results <- lapply(adpkd[, numeric_columns], shapiro.test)

shapiro_results
```

```{r,echo=FALSE}
# Get correlation matrix
numeric_columns <- sapply(adpkd, is.numeric)
cor_matrix <- cor(adpkd[, numeric_columns])   

#visualize correlation matrix
print(cor_matrix)

```


```{r, echo=FALSE}
# Get highly correlated features
high_correlations <- which(abs(cor_matrix) > 0.8, arr.ind = TRUE)

high_correlations_pairs <- data.frame(
  Column1 = rownames(cor_matrix)[high_correlations[, 1]],
  Column2 = colnames(cor_matrix)[high_correlations[, 2]],
  Correlation = cor_matrix[high_correlations]
)

# Print the result
high_correlations_pairs

#Finds that lbp4-lbp3, and lbp4-lbp1, are the only feature pairs with a correlation greater than 0.8

```


```{r, echo=FALSE}
# Address multicolinearity
# ibp4 is highly correlated with both lbp1 and lbp3, lbp4 is also the least correlated with our outcome variables so that is the feature we will delete to address the multicolinearity 

adpkd_no_multico <- adpkd[, -which(names(adpkd)== "lbp4")]
head(adpkd_no_multico)

#adpkd_no_multico is the dataset without lbp4 to address issues with multicolinearity
```


```{r, echo=FALSE}
# box plots of independent variables 
vars_to_transform <- setdiff(names(adpkd_no_multico), c("Subject.ID", "tkvht_visit2","progression","tkvht_change"))
x_variables <- adpkd_no_multico[, vars_to_transform]

for (col in names(x_variables)) {
  boxplot(x_variables[[col]], main = paste("Figure 2: Boxplot of", col), ylab = col)
}

# While the box plots do show that we have outliers we do not have any evidence that these outliers are an error, for now we will leave them in until we decide on the features that we are keeping and then we will revisit how to address them (possibly z-score 3 std's away)
```


```{r,echo=FALSE}
# Because the values are not normally distributed we decided to use normalization over standardization 

#normalizing x values to put them on a similar scale for analysis 
adpkd_x_vars_normalized <- as.data.frame(lapply(x_variables, function(x) {
  (x - min(x)) / (max(x) - min(x))
}))

head(adpkd_x_vars_normalized)

#normalized to a range between 0 and 1
```


Task 1: For part 2 and part 3 we should do a linear regression, a ridge regression and a lasso regression so that we can compare them and decide on which linear model works best, then we can choose the model that gives us the best AIC and lowest mse as our final model for that part 

```{r,echo=FALSE}
y_variables <- adpkd_no_multico[, c("Subject.ID", "tkvht_visit2","progression","tkvht_change")]
y_variables
```

```{r,echo=FALSE}
combined_normalized <- cbind(adpkd_x_vars_normalized, y_variables)
combined_normalized


# code to do a 70/30 split on combined normalized
set.seed(123)
#randomly split data into 70/30 
sample <- sample(c(TRUE, FALSE), nrow(combined_normalized), replace=TRUE,prob=c(0.7,0.3))
training <-combined_normalized[sample, ]
testing <- combined_normalized[!sample,]

```

```{r,echo=FALSE}
#train linear models

#linear model using tkvht_base as only predictor
model_tkv_lm <- lm(tkvht_change ~tkvht_base, data=training)
summary(model_tkv_lm)

#linear model using image featuring as predictors

#linear model: 

model_image_lm <- lm(tkvht_change ~ geom1 + geom2 + #image feature based on kidney geometry information
    gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + 
    glcm1 + glcm2 + #image feature based on gray level co-occurrence matrix
    txti1 + txti2 + txti3 + txti4 + txti5 + #image feature based on image textures
    lbp1 + lbp2 + lbp3 + lbp5, # local binary pattern)
    data = training)


model_both_lm <- lm(tkvht_change ~ tkvht_base + geom1 + geom2 +  gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + glcm1 + glcm2 + txti1 + txti2 + txti3 + txti4 + txti5 +  lbp1 + lbp2 + lbp3 + lbp5,  data = training)

#extract residuals for 

model_tkv_fitted<- predict(model_tkv_lm)
model_tkv_resid <-  resid(model_tkv_lm)

model_image_fitted<- predict(model_image_lm)
model_image_resid <-  resid(model_image_lm)

model_both_fitted<- predict(model_both_lm)
model_both_resid <-  resid(model_both_lm)



# check assumptions of linear regression on this model
#outliers appear to skew equal variance, normality, and linearity

#plot residuals
ggplot(data= NULL, aes(x=model_tkv_fitted,y=model_tkv_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure 3: tkv change lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_tkv_resid, main = "figure 4:Q-Q Plot of Residuals for tkv base lm")
qqline(model_tkv_resid, col= "red")


#plot residuals of lm image featuring 
ggplot(data= NULL, aes(x=model_image_fitted,y=model_image_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure 3: model imaging lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_image_resid, main = "figure 4: Q-Q Plot of Residuals for model imaging lm")
qqline(model_image_resid, col= "red")

#appears as though normality could be violated, this could be due to outliers

#plot residuals
ggplot(data= NULL, aes(x=model_both_fitted,y=model_both_resid)) +
  geom_point()+
  geom_hline(yintercept = 0, linetype="dashed", color = "red")+
  labs(title = "figure 3: tkv change lm residuals vs fitted",
       x = "fitted values",
       y= "residual values")+
  theme_minimal()

#qqplot to check normality
qqnorm(model_tkv_resid, main = "Figure 4:Q-Q Plot of Residuals for model imaging lm")
qqline(model_tkv_resid, col= "red")

```

Method 2: Lasso

```{r, echo=FALSE}

# for imaging
X_image <- as.matrix(training[, c("geom1", "geom2", "gabor1", "gabor2", "gabor3", "gabor4", "gabor5", 
                                  "glcm1", "glcm2", "txti1", "txti2", "txti3", "txti4", "txti5", "lbp1", "lbp2", "lbp3", "lbp5")])
y_image <- training$tkvht_change  # Response variable

# Fit Lasso model with a specific lambda
lasso_image <- glmnet(X_image, y_image, alpha = 1, lambda = 0.1)  # Use lambda=0.1 as an example
lasso_image<- cv.glmnet(X_image,y_image,alpha=1)
best_lasso_lambda<-lasso_image$lambda.min
#returns 1.43536

# Get the coefficients
#lasso_image$beta

#for both: 

# Prepare the data
X_both <- as.matrix(training[, c("tkvht_base", "geom1", "geom2", "gabor1", "gabor2", "gabor3", "gabor4", "gabor5", 
                                  "glcm1", "glcm2", "txti1", "txti2", "txti3", "txti4", "txti5", "lbp1", "lbp2", "lbp3", "lbp5")])
y_both <- training$tkvht_change  # Response variable

# Fit Lasso model with a specific lambda
lasso_both <- glmnet(X_both, y_both, alpha = 1, lambda = 0.1)  # Use lambda=0.1 as an example

lasso_both_lambda <- cv.glmnet(X_both,y_both,alpha=1)
best_both_lambda <- lasso_both_lambda$lambda.min
best_both_lambda #returns 2.508332but increases RMSE


```


Ridge


```{r, echo=FALSE}


# Prepare the data for Ridge regression for image featuring
X_image <- as.matrix(training[, c("geom1", "geom2", "gabor1", "gabor2", "gabor3", "gabor4", "gabor5", 
                                  "glcm1", "glcm2", "txti1", "txti2", "txti3", "txti4", "txti5", "lbp1", "lbp2", "lbp3", "lbp5")])
y_image <- training$tkvht_change  # Response variable

# Fit Ridge model (alpha = 0 for Ridge)
ridge_image <- glmnet(X_image, y_image, alpha = 0, lambda = 0.1)  # You can choose an appropriate lambda value

ridge_image_lambda <- cv.glmnet(X_image,y_image, alpha=0)
best_lambda_image <-ridge_image_lambda$lambda.min
best_lambda_image
#returns best lambda value of 2285.499 but this will increase RMSE- underfits?




# Prepare the data for Ridge regression 
X_both <- as.matrix(training[, c("tkvht_base", "geom1", "geom2", "gabor1", "gabor2", "gabor3", "gabor4", "gabor5", 
                                  "glcm1", "glcm2", "txti1", "txti2", "txti3", "txti4", "txti5", "lbp1", "lbp2", "lbp3", "lbp5")])
y_both <- training$tkvht_change  # Response variable

# Fit Ridge model (alpha = 0 for Ridge)
ridge_both <- glmnet(X_both, y_both, alpha = 0, lambda = 0.1)  # You can choose an appropriate lambda value

ridge_both_lambda <-cv.glmnet(X_both, y_both, alpha=0)
#best_lambda_both <-ridge_both_lambda$lambda.min
#best_lambda_both 
#returns 2508.332 but this increases RMSE- underfits?



```

```{r}

# Model selection

# AIC for all models (including the two additional Linear models)
aic_tkv_lm <- AIC(model_tkv_lm)   # Linear (TKV Base)
aic_image_lm <- AIC(model_image_lm) # Linear (Image)
aic_both_lm <- AIC(model_both_lm)   # Linear (Both)

# MSE for all models (on Training Data)
# Predict and calculate MSE for Linear Models
lm_image_pred <- predict(model_image_lm, newdata = training)  # Linear (Image)
mse_lm_image <- mean((training$tkvht_change - lm_image_pred)^2)

# MSE for Linear (TKV Base)
lm_tkv_pred <- predict(model_tkv_lm, newdata = training)  # Linear (TKV Base)
mse_lm_tkv <- mean((training$tkvht_change - lm_tkv_pred)^2)

# MSE for Linear (Both)
lm_both_pred <- predict(model_both_lm, newdata = training)  # Linear (Both)
mse_lm_both <- mean((training$tkvht_change - lm_both_pred)^2)

# Lasso Model - Image
lasso_image_pred <- predict(lasso_image, s = 0.1, newx = X_image)
mse_lasso_image <- mean((training$tkvht_change - lasso_image_pred)^2)

# Ridge Model - Image
ridge_image_pred <- predict(ridge_image, s = 0.1, newx = X_image)
mse_ridge_image <- mean((training$tkvht_change - ridge_image_pred)^2)

# Lasso Model - Both
lasso_both_pred <- predict(lasso_both, s = 0.1, newx = X_both)
mse_lasso_both <- mean((training$tkvht_change - lasso_both_pred)^2)

# Ridge Model - Both
ridge_both_pred <- predict(ridge_both, s = 0.1, newx = X_both)
mse_ridge_both <- mean((training$tkvht_change - ridge_both_pred)^2)


# RMSE Calculation (Square root of MSE)
rmse_lm_tkv <- sqrt(mse_lm_tkv)
rmse_lm_image <- sqrt(mse_lm_image)
rmse_lm_both <- sqrt(mse_lm_both)

rmse_lasso_image <- sqrt(mse_lasso_image)
rmse_ridge_image <- sqrt(mse_ridge_image)
rmse_lasso_both <- sqrt(mse_lasso_both)
rmse_ridge_both <- sqrt(mse_ridge_both)

# Store AIC, MSE, and RMSE results in a data frame
results <- data.frame(
  Model = c("Linear (TKV Base)", "Linear (Image)", "Linear (Both)", 
            "Lasso (Image)", "Ridge (Image)", "Lasso (Both)", "Ridge (Both)"),
  AIC = c(aic_tkv_lm, aic_image_lm, aic_both_lm, NA, NA, NA, NA),
  MSE = c(mse_lm_tkv, mse_lm_image, mse_lm_both, 
          mse_lasso_image, mse_ridge_image, mse_lasso_both, mse_ridge_both),
  RMSE = c(rmse_lm_tkv, rmse_lm_image, rmse_lm_both, 
           rmse_lasso_image, rmse_ridge_image, rmse_lasso_both, rmse_ridge_both)
)


kable(results, caption = "Table 2: Model Comparison: AIC, MSE, and RMSE (Training Data)", digits = 4)


```

Testing  

```{r}

#For ridge both
# Prepare the testing data (convert to matrix, same features used for training)
X_test <- as.matrix(testing[, c("tkvht_base", "geom1", "geom2", "gabor1", "gabor2", "gabor3", "gabor4", "gabor5", 
                                "glcm1", "glcm2", "txti1", "txti2", "txti3", "txti4", "txti5", "lbp1", "lbp2", "lbp3", "lbp5")])

X_test_i <- as.matrix(testing[, c("geom1", "geom2", "gabor1", "gabor2", "gabor3", "gabor4", "gabor5", 
                                "glcm1", "glcm2", "txti1", "txti2", "txti3", "txti4", "txti5", "lbp1", "lbp2", "lbp3", "lbp5")])

X_test_s <- as.matrix(testing[, "tkvht_base"])

# Use the Ridge models to make predictions on the testing data
ridge_both_pred_test <- predict(ridge_both, s = 0.1, newx = X_test)
ridge_image_pred_test <- predict(ridge_image,s=0.1, newx=X_test_i)

#using Lasso models to make predictions on the testing data

lasso_image_pred_test <-predict(lasso_image,s=0.1, newx = X_test_i)
lasso_both_pred_test <- predict(lasso_both,s=0.1,newx = X_test)


#using linear (both and just image)

both_lm_pred_test <- predict(model_both_lm, newx = X_test)
lm_image_pred_test <- predict(model_image_lm, newx = X_test)
tkv_lm_pred_test <- predict(model_tkv_lm, newx = X_test_s)


# Calculate MSE for all models
mse_ridge_both_test <- mean((testing$tkvht_change - ridge_both_pred_test)^2)
mse_ridge_image_test <- mean((testing$tkvht_change - ridge_image_pred_test)^2)
mse_lasso_both_test <- mean((testing$tkvht_change - lasso_both_pred_test)^2)
mse_lasso_image_test <- mean((testing$tkvht_change - lasso_image_pred_test)^2)
mse_both_lm_test <- mean((testing$tkvht_change - both_lm_pred_test)^2)
mse_lm_image_test <- mean((testing$tkvht_change - lm_image_pred_test)^2)
mse_tkv_lm_test <- mean((testing$tkvht_change - tkv_lm_pred_test)^2)

# Calculate RMSE for all models
rmse_ridge_both_test <- sqrt(mse_ridge_both_test)
rmse_ridge_image_test <- sqrt(mse_ridge_image_test)
rmse_lasso_both_test <- sqrt(mse_lasso_both_test)
rmse_lasso_image_test <- sqrt(mse_lasso_image_test)
rmse_both_lm_test <- sqrt(mse_both_lm_test)
rmse_lm_image_test <- sqrt(mse_lm_image_test)
rmse_tkv_lm_test <- sqrt(mse_tkv_lm_test)

# Create a data frame for the final evaluation metrics
final_metrics <- data.frame(
  Model = c("Ridge (Both)", "Ridge (Image)",  
            "Linear (Both)", "Linear (Image)", "Linear (TKV)"),
  MSE = c(round(mse_ridge_both_test, 4), round(mse_ridge_image_test, 4), 
          #round(mse_lasso_both_test, 4), round(mse_lasso_image_test, 4), 
          round(mse_both_lm_test, 4), round(mse_lm_image_test, 4), 
          round(mse_tkv_lm_test, 4)),
  RMSE = c(round(rmse_ridge_both_test, 4), round(rmse_ridge_image_test, 4), 
           #round(rmse_lasso_both_test, 4), round(rmse_lasso_image_test, 4), 
           round(rmse_both_lm_test, 4), round(rmse_lm_image_test, 4), 
           round(rmse_tkv_lm_test, 4))
)

# Output the results in a table

kable(final_metrics, caption = "Table 3: Testing Data Model Evaluation Metrics (MSE and RMSE)", digits = 4)
```






Logistic regression


```{r, echo=FALSE}

#fit logistic regression model

tkvht_base_glm <- glm(progression ~ tkvht_base, family = "binomial", data = training)

summary(tkvht_base_glm)

model_imaging_log <- glm(progression ~ geom1 + geom2 + gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + glcm1 + glcm2 + txti1 + txti2 + txti3 + txti4 + txti5 + lbp1 + lbp2 + lbp3 + lbp5, data = training )

summary(model_imaging_log)

model_both_log <- glm(progression ~ tkvht_base +geom1 + geom2 + gabor1 + gabor2 + gabor3 + gabor4 + gabor5 + glcm1 + glcm2 + txti1 + txti2 + txti3 + txti4 + txti5 + lbp1 + lbp2 + lbp3 + lbp5, data = training )


```
Lasso and ridge for model imaging 

```{r, echo=FALSE}

# Prepare the data for logistic regression with Lasso regularization (L1)
X_lasso_i <- as.matrix(training[, c( "geom1", "geom2", "gabor1", "gabor2", "gabor3", "gabor4", "gabor5", 
                                  "glcm1", "glcm2", "txti1", "txti2", "txti3", "txti4", "txti5", "lbp1", "lbp2", "lbp3", "lbp5")])
y_lasso_i <- training$progression  # Binary outcome variable

# Fit Lasso logistic regression (alpha = 1 for Lasso)
lasso_logit_i <- glmnet(X_lasso_i, y_lasso_i, family = "binomial", alpha = 1, lambda = 0.1)  # Choose a lambda value





# Fit Ridge logistic regression (alpha = 0 for Ridge) L2 Regularization
ridge_logit_i <- glmnet(X_lasso_i, y_lasso_i, family = "binomial", alpha = 0, lambda = 0.1)  # Choose a lambda value




```




Lasso and ridge for both 

```{r, echo=FALSE}

# Prepare the data for logistic regression with Lasso regularization (L1)
X_lasso <- as.matrix(training[, c("tkvht_base", "geom1", "geom2", "gabor1", "gabor2", "gabor3", "gabor4", "gabor5", 
                                  "glcm1", "glcm2", "txti1", "txti2", "txti3", "txti4", "txti5", "lbp1", "lbp2", "lbp3", "lbp5")])
y_lasso <- training$progression  # Binary outcome variable

# Fit Lasso logistic regression (alpha = 1 for Lasso)
lasso_logit <- glmnet(X_lasso, y_lasso, family = "binomial", alpha = 1, lambda = 0.1)  # Choose a lambda value





# Fit Ridge logistic regression (alpha = 0 for Ridge) L2 Regularization
ridge_logit <- glmnet(X_lasso, y_lasso, family = "binomial", alpha = 0, lambda = 0.1)  # Choose a lambda value





```






```{r, echo=FALSE}

#pulls warning about using matrix as predictor. for futureproofing could look into using lasso/ridge without matricies (updated package no longer needs this i think. Fine to run our code as is)

# Generate predictions for logistic regression models
# Logistic Regression - TKV Base
logit_tkvht_base_pred <- predict(tkvht_base_glm, newdata = training, type = "response")

# Logistic Regression - Imaging
logit_imaging_pred <- predict(model_imaging_log, newdata = training, type = "response")

# Logistic Regression - Both
logit_both_pred <- predict(model_both_log, newdata = training, type = "response")

# Generate predictions for Lasso and Ridge logistic regression models
# Lasso Logistic Regression - Imaging Data
lasso_logit_imaging_pred <- predict(lasso_logit_i, s = 0.1, newx = X_lasso_i, type = "response")

# Ridge Logistic Regression - Imaging Data
ridge_logit_imaging_pred <- predict(ridge_logit_i, s = 0.1, newx = X_lasso_i, type = "response")

# Lasso Logistic Regression - Combined (TKV Base + Imaging Data)
lasso_logit_both_pred <- predict(lasso_logit, s = 0.1, newx = X_lasso, type = "response")

# Ridge Logistic Regression - Combined (TKV Base + Imaging Data)
ridge_logit_both_pred <- predict(ridge_logit, s = 0.1, newx = X_lasso, type = "response")

# Calculate ROC for each model
roc_tkvht_base <- roc(training$progression, logit_tkvht_base_pred)
roc_imaging <- roc(training$progression, logit_imaging_pred)
roc_both <- roc(training$progression, logit_both_pred)

roc_lasso_imaging <- roc(training$progression, lasso_logit_imaging_pred)
roc_ridge_imaging <- roc(training$progression, ridge_logit_imaging_pred)

roc_lasso_both <- roc(training$progression, lasso_logit_both_pred)
roc_ridge_both <- roc(training$progression, ridge_logit_both_pred)

# Calculate AUC for each model
auc_tkvht_base <- auc(roc_tkvht_base)
auc_imaging <- auc(roc_imaging)
auc_both <- auc(roc_both)

auc_lasso_imaging <- auc(roc_lasso_imaging)
auc_ridge_imaging <- auc(roc_ridge_imaging)

auc_lasso_both <- auc(roc_lasso_both)
auc_ridge_both <- auc(roc_ridge_both)

# Create a comparison table for AUC values
auc_results <- data.frame(
  Model = c("Logistic (TKV Base)", "Logistic (Imaging)", "Logistic (Both)",
            "Lasso (Imaging)", "Ridge (Imaging)", "Lasso (Both)", "Ridge (Both)"),
  AUC = c(auc_tkvht_base, auc_imaging, auc_both,
          auc_lasso_imaging, auc_ridge_imaging, auc_lasso_both, auc_ridge_both))

# Display the AUC comparison table
kable(auc_results, caption = "Table 4: Model Comparison: AUC and ROC(Training Data)", digits = 4)



```




```{r,echo=FALSE}
# Convert probabilities to binary predictions (threshold = 0.5)
logit_tkvht_base_pred_bin <- ifelse(logit_tkvht_base_pred > 0.5, 1, 0)
logit_imaging_pred_bin <- ifelse(logit_imaging_pred > 0.5, 1, 0)
logit_both_pred_bin <- ifelse(logit_both_pred > 0.5, 1, 0)
lasso_logit_imaging_pred_bin <- ifelse(lasso_logit_imaging_pred > 0.5, 1, 0)
ridge_logit_imaging_pred_bin <- ifelse(ridge_logit_imaging_pred > 0.5, 1, 0)
lasso_logit_both_pred_bin <- ifelse(lasso_logit_both_pred > 0.5, 1, 0)
ridge_logit_both_pred_bin <- ifelse(ridge_logit_both_pred > 0.5, 1, 0)

# Calculate confusion matrix and metrics for Lasso and Ridge models
logit_tkvht_base_cm <- confusionMatrix(as.factor(logit_tkvht_base_pred_bin), as.factor(training$progression))
logit_imaging_cm <- confusionMatrix(as.factor(logit_imaging_pred_bin), as.factor(training$progression))
logit_both_cm <- confusionMatrix(as.factor(logit_both_pred_bin), as.factor(training$progression))
lasso_logit_imaging_cm <- confusionMatrix(as.factor(lasso_logit_imaging_pred_bin), as.factor(training$progression))
ridge_logit_imaging_cm <- confusionMatrix(as.factor(ridge_logit_imaging_pred_bin), as.factor(training$progression))
lasso_logit_both_cm <- confusionMatrix(as.factor(lasso_logit_both_pred_bin), as.factor(training$progression))
ridge_logit_both_cm <- confusionMatrix(as.factor(ridge_logit_both_pred_bin), as.factor(training$progression))

# Extract accuracy and F1 score from the confusion matrix
logit_tkvht_base_accuracy   <- logit_tkvht_base_cm$overall['Accuracy']
logit_imaging_accuracy <- logit_imaging_cm$overall['Accuracy']
logit_both_accuracy<- logit_both_cm$overall['Accuracy']
lasso_logit_imaging_accuracy <- lasso_logit_imaging_cm$overall['Accuracy']
ridge_logit_imaging_accuracy <- ridge_logit_imaging_cm$overall['Accuracy']
lasso_logit_both_accuracy <- lasso_logit_both_cm$overall['Accuracy']
ridge_logit_both_accuracy <- ridge_logit_both_cm$overall['Accuracy']

logit_tkvht_base_f1 <- logit_tkvht_base_cm$byClass['F1']
logit_imaging_f1 <- logit_imaging_cm$byClass['F1']
logit_both_f1 <- logit_both_cm$byClass['F1']
lasso_logit_imaging_f1 <- lasso_logit_imaging_cm$byClass['F1']
ridge_logit_imaging_f1 <- ridge_logit_imaging_cm$byClass['F1']
lasso_logit_both_f1 <- lasso_logit_both_cm$byClass['F1']
ridge_logit_both_f1 <- ridge_logit_both_cm$byClass['F1']

# Update the comparison table with accuracy and F1
auc_results <- data.frame(
  Model = c("Logistic (TKV Base)", "Logistic (Imaging)", "Logistic (Both)",
            "Lasso (Imaging)", "Ridge (Imaging)", "Lasso (Both)", "Ridge (Both)"),
  AUC = c(auc_tkvht_base, auc_imaging, auc_both, 
          auc_lasso_imaging, auc_ridge_imaging, auc_lasso_both, auc_ridge_both),
  Accuracy = c(logit_tkvht_base_accuracy, logit_imaging_accuracy, logit_both_accuracy, 
               lasso_logit_imaging_accuracy, ridge_logit_imaging_accuracy,
               lasso_logit_both_accuracy, ridge_logit_both_accuracy),
  F1 = c(logit_tkvht_base_f1, logit_imaging_f1, logit_both_f1, 
         lasso_logit_imaging_f1, ridge_logit_imaging_f1,
         lasso_logit_both_f1, ridge_logit_both_f1)
)

# Display the updated table
kable(auc_results, caption = "Table 4: Model Comparison: AUC, Accuracy, and F1-Score (Training Data)", digits = 4)

```

Testing:

```{r,echo=FALSE}

#make testing predictions on unseen data
test_predictions <- predict(model_imaging_log, newdata = testing, type = "response")

#compute ROC and AUC
roc_curve <-roc(testing$progression,test_predictions)

#AUC
auc_value <-auc(roc_curve)

print(paste("AUC For Logistic Regression (Imaging) Model:",round(auc_value, 4)))

plot(roc_curve, main = "ROC Curve For Logistic Regression (Imaging)", col = "blue",lwd=2)

# Generate confusion matrix using caret
#conf_matrix <- confusionMatrix(factor(predictions), factor(testing$progression))

# Print the confusion matrix
#print(conf_matrix)

```





```{r}

#prepare testing data for lasso and ridge
# Prepare the data for logistic regression with Lasso regularization (L1)
X_lasso_ti <- as.matrix(testing[, c( "geom1", "geom2", "gabor1", "gabor2", "gabor3", "gabor4", "gabor5", 
                                  "glcm1", "glcm2", "txti1", "txti2", "txti3", "txti4", "txti5", "lbp1", "lbp2", "lbp3", "lbp5")])
y_lasso_ti <- testing$progression  # Binary outcome variable

# Prepare the data for logistic regression with Lasso regularization (L1)
X_lasso <- as.matrix(testing[, c( "tkvht_base", "geom1", "geom2", "gabor1", "gabor2", "gabor3", "gabor4", "gabor5", 
                                  "glcm1", "glcm2", "txti1", "txti2", "txti3", "txti4", "txti5", "lbp1", "lbp2", "lbp3", "lbp5")])
y_lasso <- testing$progression  # Binary outcome variable


#make testing predictions on unseen data
test_tkv_log_pred <- predict(tkvht_base_glm, newdata = testing, type ="response")
test_predictions <- predict(model_imaging_log, newdata = testing, type = "response")
test_logit_tkvt <-predict(tkvht_base_glm,newdata=testing, type = "response")
test_logit_both <-predict(model_both_log,newdata = testing,type ="response")
test_las_logit_imaging <- predict(lasso_logit_i, newx = X_lasso_ti, s = 0.1, type = "response")
test_las_logit_both_pred <-predict(lasso_logit, newx = X_lasso, s = 0.1, type = "response")
test_ridge_imaging_pred <- predict(ridge_logit_i, newx = X_lasso_ti, s = 0.1, type = "response")
test_ridge_logit_both_pred <-predict(ridge_logit, newx = X_lasso, s = 0.1, type = "response")

#threshold binary predictions 
test_tkv_pred_bin <- ifelse(test_tkv_log_pred >0.5,1,0)
test_pred_binary <- ifelse(test_predictions > 0.5, 1, 0)
test_logit_imaging_pred_bin <- ifelse(test_logit_tkvt > 0.5, 1, 0)
test_logit_both_pred_bin <- ifelse(test_logit_both > 0.5, 1, 0)
test_lasso_logit_imaging_pred_bin <- ifelse(test_las_logit_imaging > 0.5, 1, 0)
test_ridge_logit_imaging_pred_bin <- ifelse(test_ridge_imaging_pred > 0.5, 1, 0)
test_lasso_logit_both_pred_bin <- ifelse(test_ridge_imaging_pred > 0.5, 1, 0)
test_ridge_logit_both_pred_bin <- ifelse(test_ridge_logit_both_pred > 0.5, 1, 0)


# Confusion Matrix
test_tkv_cm <- confusionMatrix(as.factor(test_tkv_pred_bin), as.factor(testing$progression))
test_cm <- confusionMatrix(as.factor(test_pred_binary), as.factor(testing$progression))
test_logit_imaging_cm <- confusionMatrix(as.factor(test_logit_imaging_pred_bin), as.factor(testing$progression))
test_logit_both_cm <- confusionMatrix(as.factor(test_logit_both_pred_bin), as.factor(testing$progression))
test_lasso_logit_imaging_cm <- confusionMatrix(as.factor(test_lasso_logit_imaging_pred_bin), as.factor(testing$progression))
test_ridge_logit_imaging_cm <- confusionMatrix(as.factor(test_ridge_logit_imaging_pred_bin), as.factor(testing$progression))
test_lasso_logit_both_cm <- confusionMatrix(as.factor(test_lasso_logit_both_pred_bin), as.factor(testing$progression))
test_ridge_logit_both_cm <- confusionMatrix(as.factor(test_ridge_logit_both_pred_bin), as.factor(testing$progression))


# Extract individual metrics from the confusion matrix
test_accuracy <- test_cm$overall['Accuracy']
test_f1 <- test_cm$byClass['F1']
test_precision <- test_cm$byClass['Precision']
test_recall <- test_cm$byClass['Recall']
test_specificity <- test_cm$byClass['Specificity']

# For Logistic (Both)
test_logit_both_accuracy <- test_logit_both_cm$overall['Accuracy']
test_logit_both_f1 <- test_logit_both_cm$byClass['F1']
test_logit_both_precision <- test_logit_both_cm$byClass['Precision']
test_logit_both_recall <- test_logit_both_cm$byClass['Recall']
test_logit_both_specificity <- test_logit_both_cm$byClass['Specificity']

# For Lasso Logistic (Imaging)
test_lasso_logit_imaging_accuracy <- test_lasso_logit_imaging_cm$overall['Accuracy']
test_lasso_logit_imaging_f1 <- test_lasso_logit_imaging_cm$byClass['F1']
test_lasso_logit_imaging_precision <- test_lasso_logit_imaging_cm$byClass['Precision']
test_lasso_logit_imaging_recall <- test_lasso_logit_imaging_cm$byClass['Recall']
test_lasso_logit_imaging_specificity <- test_lasso_logit_imaging_cm$byClass['Specificity']

# For Ridge Logistic (Imaging)
test_ridge_logit_imaging_accuracy <- test_ridge_logit_imaging_cm$overall['Accuracy']
test_ridge_logit_imaging_f1 <- test_ridge_logit_imaging_cm$byClass['F1']
test_ridge_logit_imaging_precision <- test_ridge_logit_imaging_cm$byClass['Precision']
test_ridge_logit_imaging_recall <- test_ridge_logit_imaging_cm$byClass['Recall']
test_ridge_logit_imaging_specificity <- test_ridge_logit_imaging_cm$byClass['Specificity']

# For Lasso Logistic (Both)
test_lasso_logit_both_accuracy <- test_lasso_logit_both_cm$overall['Accuracy']
test_lasso_logit_both_f1 <- test_lasso_logit_both_cm$byClass['F1']
test_lasso_logit_both_precision <- test_lasso_logit_both_cm$byClass['Precision']
test_lasso_logit_both_recall <- test_lasso_logit_both_cm$byClass['Recall']
test_lasso_logit_both_specificity <- test_lasso_logit_both_cm$byClass['Specificity']

# For Ridge Logistic (Both)
test_ridge_logit_both_accuracy <- test_ridge_logit_both_cm$overall['Accuracy']
test_ridge_logit_both_f1 <- test_ridge_logit_both_cm$byClass['F1']
test_ridge_logit_both_precision <- test_ridge_logit_both_cm$byClass['Precision']
test_ridge_logit_both_recall <- test_ridge_logit_both_cm$byClass['Recall']
test_ridge_logit_both_specificity <- test_ridge_logit_both_cm$byClass['Specificity']


# Create a performance summary table for all models (excluding ROC and AUC)
performance_summary <- data.frame(
  Model = c("Logistic (Imaging)", "Logistic (TKV)", "Logistic (Both)", 
            "Lasso (Imaging)", "Lasso (Both)", "Ridge (Imaging)", "Ridge (Both)"),
  Accuracy = c(test_accuracy, test_tkv_cm$overall['Accuracy'], test_logit_both_accuracy,
               test_lasso_logit_imaging_accuracy, test_lasso_logit_both_accuracy, 
               test_ridge_logit_imaging_accuracy, test_ridge_logit_both_accuracy),
  Precision = c(test_precision, test_tkv_cm$byClass['Precision'], test_logit_both_precision,
                test_lasso_logit_imaging_precision, test_lasso_logit_both_precision,
                test_ridge_logit_imaging_precision, test_ridge_logit_both_precision),
  Recall = c(test_recall, test_tkv_cm$byClass['Recall'], test_logit_both_recall,
             test_lasso_logit_imaging_recall, test_lasso_logit_both_recall,
             test_ridge_logit_imaging_recall, test_ridge_logit_both_recall),
  F1_Score = c(test_f1, test_tkv_cm$byClass['F1'], test_logit_both_f1,
               test_lasso_logit_imaging_f1, test_lasso_logit_both_f1, 
               test_ridge_logit_imaging_f1, test_ridge_logit_both_f1),
  Specificity = c(test_specificity, test_tkv_cm$byClass['Specificity'], test_logit_both_specificity,
                  test_lasso_logit_imaging_specificity, test_lasso_logit_both_specificity,
                  test_ridge_logit_imaging_specificity, test_ridge_logit_both_specificity)
)

# Display the performance summary
print(performance_summary)


```




```{r,echo=FALSE}

# 1. Logistic regression model with tkvht_base (Base) prediction
roc_tkvht_base <- roc(testing$progression, test_tkv_log_pred)
auc_tkvht_base <- auc(roc_tkvht_base)

# 2. Logistic regression model with imaging (imaging model)
roc_imaging <- roc(testing$progression, test_predictions)
auc_imaging <- auc(roc_imaging)

# 3. Logistic regression model with tkvht_base (Base) for test_logit_tkvt
roc_tkvht_logit <- roc(testing$progression, test_logit_tkvt)
auc_tkvht_logit <- auc(roc_tkvht_logit)

# 4. Logistic regression model with both variables (both model)
roc_both_logit <- roc(testing$progression, test_logit_both)
auc_both_logit <- auc(roc_both_logit)

# 5. Lasso regression model on imaging data (Lasso regularization on X_lasso_ti)
roc_lasso_imaging <- roc(testing$progression, test_las_logit_imaging)
auc_lasso_imaging <- auc(roc_lasso_imaging)

# 6. Lasso regression model on both data (Lasso regularization on X_lasso)
roc_lasso_both <- roc(testing$progression, test_las_logit_both_pred)
auc_lasso_both <- auc(roc_lasso_both)

# 7. Ridge regression model on imaging data (Ridge regularization on X_lasso_ti)
roc_ridge_imaging <- roc(testing$progression, test_ridge_imaging_pred)
auc_ridge_imaging <- auc(roc_ridge_imaging)

# 8. Ridge regression model on both data (Ridge regularization on X_lasso)
roc_ridge_both <- roc(testing$progression, test_ridge_logit_both_pred)
auc_ridge_both <- auc(roc_ridge_both)

# Create a data frame to store AUC values for each model
auc_table <- data.frame(
  Model = c("Logistic (TVK Base)", 
            "Logistic (Imaging)", 
            "Logistic (Both Variables)", 
            "Lasso (Imaging)", 
            "Lasso (Both Variables)", 
            "Ridge (Imaging)", 
            "Ridge (Both Variables)"),
  AUC = c(auc_tkvht_base, 
          auc_imaging, 
          auc_both_logit, 
          auc_lasso_imaging, 
          auc_lasso_both, 
          auc_ridge_imaging, 
          auc_ridge_both)
)

# Print the table
#print(auc_table)

# Round AUC values to 4 decimal places
auc_table$AUC <- round(auc_table$AUC, 4)

# Create a clean table with kable
kable(auc_table, 
      caption = "Table 5: Comparison of AUC Values for All Models (Testing)", 
      col.names = c("Model", "AUC"), 
      format = "pipe")  # For markdown tables

```
